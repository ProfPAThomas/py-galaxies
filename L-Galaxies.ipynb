{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implementation of L-Galaxies\n",
    "\n",
    "This is a playground to test out the possibility of using `python` as an interface into L-Galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import astropy.constants as c\n",
    "import astropy.units as u\n",
    "import gc\n",
    "import h5py\n",
    "h5py.enable_ipython_completer()\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development limiter\n",
    "nHaloMax=10000\n",
    "\n",
    "# Debug/testing switch\n",
    "debugFlag=True\n",
    "\n",
    "# Verbosity\n",
    "verbosity=1 # 0 - Major program steps only; 1/2 - Major/minor Counters; 3 - Debugging diags.\n",
    "\n",
    "# Script parameters\n",
    "file_parameters='input/input.yml'\n",
    "displayParameters=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in parameters, graph file, etc.\n",
    "\n",
    "parameters=yaml.load(open(file_parameters),Loader=yaml.FullLoader)\n",
    "if displayParameters:\n",
    "    for item in parameters:\n",
    "        print(\"{:20s}: {}\".format(item,parameters[item]))\n",
    "\n",
    "graphFile=parameters['inputFiles']['graphFile']\n",
    "graphData=h5py.File(graphFile,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure for halos\n",
    "\n",
    "This is an interesting problem.  We have many requirements:\n",
    "- Must be fast – does this remove the possibility of using objects?\n",
    "- Must be flexible enough to respond to parameter choices (ideally at run time).\n",
    "- Must allow for variable-length arrays – I think that each halo will individually need to track what fraction of material it inherits from each progenitor.\n",
    "\n",
    "I think that the object-oriented way of doing it, as below, can easily adapt to run-time choices because it does not use long arrays.\n",
    "\n",
    "I have initially coded it using:\n",
    "- a list of graphs;\n",
    "- each graph is a dictionary of snapshots;\n",
    "- each snapshot is a dictionary of halos;\n",
    "- each halo is an instance of the `haloProperties` class.  \n",
    "\n",
    "There is a numpy.object dtype that would allow one to make that numpy arrays but I don't know if it offers any performance advantages or disadvantages.  The numpy objects can have arbitrary data added to them, but again I don't know if this flexibility means that they will be very slow (due to having to continually shift things around in memory).\n",
    "\n",
    "This is all very far from the current method that we have in L-Galaxies of defining a galaxy structure at compile time.\n",
    "\n",
    "## Data structure in graph HDF5 files\n",
    "\n",
    "Each graph is a group in the root `['/']` with labels `graphID` that appear to be non-consecutive: `group size=918`; `max(graphID)=1000`.  However, this could be because this is a subset of all graphs – in general may be working with subsets, so don't assume consecutive.\n",
    "\n",
    "Each snapshot is a group in `['/<graphID>']` with labels `snapID` running over all snapshots.\n",
    "\n",
    "Each halo is a group in `['/<graphID>/<snapID>']` with labels `haloID` that appear to run consecutively from 0, with `haloID` increasing with `snapID`.\n",
    "<b>Note: they are in increasing string order, not numerical order.  This is a feature that needs fixing or it wil break the code at some point.</b><br>\n",
    "Halos have attributes:\n",
    "* `catalogID` – ID in the original halo catalogue\n",
    "* `concentration` – ?\n",
    "* `halo_mass` – mass in Msun\n",
    "* `halo_nPart` – number of particles\n",
    "\n",
    "and datasets:\n",
    "* `centre_of_mass` – `np.float64[3]` array of centroid (?) in cMpc (?)\n",
    "* `desc_haloIDs` – `np.int64[<variable>]` array of `haloID`s of decendants\n",
    "* `desc_mass_contribution` – `np.int64[<variable>]` array of number of particles in common with each descendant (? – may contain non-associated particles)\n",
    "* `halo_velocity` – `np.float64[3]` array of mean velocity in km/s (?)\n",
    "* `prog_haloIDs` – `np.int64[<variable>]` array of `progID`s of decendants\n",
    "* `prog_mass_contribution` – `np.int64[<variable>]` array of number of particles in  \n",
    "common with each progenitor (? – may contain non-associated particles)\n",
    "\n",
    "Presumably we can add more properties, as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This haloProperties class is just a container for all the halo properties.\n",
    "# It is not expected that it should have any sophisticated methods.\n",
    "# The constructer merely provides the unique labels for each halo;\n",
    "# other properties may then be added.\n",
    "# If this dynamic variable allocation is too slow, we could presumably find a way\n",
    "# to declare all the variables that we will need at the time of construction.\n",
    "class haloProperties:\n",
    "    # Constructor.\n",
    "    def __init__(self,graphID,snapID,haloID):\n",
    "        # These are (HDF5) strings\n",
    "        self.graphID=graphID\n",
    "        self.snapID=snapID\n",
    "        self.haloID=haloID\n",
    "        # Other halo properties.  Is it best to initialise to particular type or to None?\n",
    "        self.done=False\n",
    "        self.catalogID=-1\n",
    "        self.mass=0.\n",
    "        self.massBaryon=0.\n",
    "        self.mass_fromProgenitors=0.\n",
    "        self.massBaryon_fromProgenitors=0.\n",
    "        if parameters['modelSwitches']['HOD']: \n",
    "            self.massStars=0.\n",
    "            self.massStars_fromProgenitors=0.\n",
    "        # Not clear whether it is better to store information here about\n",
    "        # progenitors and descendants, which might result in variable-length\n",
    "        # data structure, or to look up from the HDF5 data file as required,\n",
    "        # which might require multiple access.\n",
    "        # If we want to specify the data size in advance, then we need to\n",
    "        # decide upon a maximum number of descendants to keep.  (I suspect\n",
    "        # that keeping as few as 3 descendants may be enough.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Most of the work to be done in external routines, probably to be coded in C for efficiency.\n",
    "\n",
    "Here we just include the high-level driver routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing halos \n",
    "def processHalo(halo):\n",
    "    if verbosity>=2: print('Processing halo ',halo.haloID)\n",
    "    if halo.done==True: \n",
    "        print('Warning: processHalo: halo ',str(halo),' already processed.')\n",
    "        return\n",
    "    readProperties(halo)\n",
    "    gatherProgenitors(halo)\n",
    "#     fixBaryonFraction(halo)\n",
    "#     fixStellarFraction(halo) # Dummy routine.\n",
    "#     outputHalo(halo)         # Is this the right place to do this?\n",
    "    halo.done=True\n",
    "    \n",
    "def readProperties(halo):\n",
    "    # Reads halo properties from the input graph file\n",
    "    halo.catalogID=graphData[halo.graphID][halo.snapID][halo.haloID].attrs.get('catalogID')\n",
    "    halo.mass=graphData[halo.graphID][halo.snapID][halo.haloID].attrs.get('halo_mass')\n",
    "    return\n",
    "\n",
    "def gatherProgenitors(halo):\n",
    "    # Collects information about material inherited from progenitors\n",
    "    for prog_haloID in graphData[halo.graphID][halo.snapID][halo.haloID]['prog_haloIDs']:\n",
    "        # Position in progenitor (lastSnap) halo list\n",
    "        if debugFlag and verbosity>=3 : print('prog_haloID =',prog_haloID)\n",
    "        prog_index_lastSnap=int(prog_haloID)-int(haloProperties_lastSnap[0].haloID) # Move out of loop?\n",
    "        if debugFlag and verbosity>=3: print('prog_index_lastSnap =',prog_index_lastSnap)\n",
    "        # Check halo association\n",
    "        # This is needed because HDF5 may store halos in a different order - \n",
    "        # if this happens, will need to add code to do a search over all halos\n",
    "        # in lastSnap.\n",
    "        if debugFlag:\n",
    "            assert int(haloProperties_lastSnap[prog_index_lastSnap].haloID) == int(prog_haloID)\n",
    "        # I am going to get Will to put in the fraction of each halo that goes to each\n",
    "        # descendant.  For now work it out.  Will need the loop over descendants anyway.\n",
    "        # Actually, that's not true if we had a dictionary, but I don't think that HDF5\n",
    "        # can handle dictionaries.\n",
    "        descMassSum=0.\n",
    "        descMass=0.\n",
    "        for desc_haloID in haloProperties_lastSnap[prog_index_lastSnap].hal['prog_haloIDs']:\n",
    "            # Do something. Progenitor may ony give part of mass to me.\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively loop over halos, doing whatever processing is required.\n",
    "# This assumes that halos properties depend only upon those halos in \n",
    "# their immediate past in the merger graph.\n",
    "\n",
    "# Note: no attempt here to include sub-halos.  Let's get halos right\n",
    "# first!\n",
    "\n",
    "# Loop over MergerGraphs.\n",
    "nHalo=0\n",
    "for graphID in graphData['/']:\n",
    "    if verbosity>=2: print('Processing graph',graphID)\n",
    "    graph=graphData[graphID]\n",
    "    # Loop over snapshots from first to last.\n",
    "    haloProperties_lastSnap = None\n",
    "#    for snap in snaps:\n",
    "    for snapID in graph:\n",
    "        if verbosity>=2: print('        snapshot',snapID)\n",
    "        snap=graph[snapID]\n",
    "        # Initialise halo properties\n",
    "        haloProperties_thisSnap=[haloProperties(graphID,snapID,haloID) for haloID in snap]\n",
    "        # Loop over halos in snapshot.\n",
    "        for halo in haloProperties_thisSnap: processHalo(halo)\n",
    "        nHalo +=1\n",
    "        if verbosity>=1: \n",
    "            if nHalo%1000==0: print('Processed {:d} halos'.format(nHalo))\n",
    "        # Once all halos have been done, update reference to lastSnap (and hence free memory)\n",
    "        del haloProperties_lastSnap\n",
    "        #gc.collect() # garbage collection -- safe but very slow.\n",
    "        haloProperties_lastSnap=haloProperties_thisSnap\n",
    "        # Delete reference to this memory to free variable for new use.\n",
    "        del haloProperties_thisSnap\n",
    "        # Temporary halt to limit to finite time\n",
    "        if nHalo==nHaloMax: assert False\n",
    "#del haloProperties_lastSnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_haloID_lastSnap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_haloID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
