{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implementation of L-Galaxies\n",
    "\n",
    "This is a playground to test out the possibility of using `python` as an interface into L-Galaxies.\n",
    "\n",
    "Abbreviations used:\n",
    "* desc   – descendent\n",
    "* gal(s) – galax(y|ies)\n",
    "* prog   – progenitor\n",
    "* sub(s) – subhalo(s)\n",
    "\n",
    "List index indentifiers:\n",
    "* _gid – relative to the graph\n",
    "* _sid - relative to the snap\n",
    "\n",
    "– galaxies/orphans do not need an index identifier as they are numpy arrays defined per snap\n",
    "\n",
    "Ptyhon type identifiers:\n",
    "* C_ - class\n",
    "* D_ - numpy dtype\n",
    "* F_ - function\n",
    "* b_ - boolean variable\n",
    "* c_ - constant (value may be set during parameter initialisation)\n",
    "* [ijk]_ - variable counter (integer)\n",
    "* n_ - total counter (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of generic python routines\n",
    "\n",
    "import astropy.constants as c\n",
    "import astropy.units as u\n",
    "#import gc\n",
    "import h5py\n",
    "import numpy as np\n",
    "np.seterr(all='raise')\n",
    "import pickle\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Switch on traceback for warnings\n",
    "import traceback\n",
    "import warnings\n",
    "def warn_with_traceback(message, category, filename, lineno, file=None, line=None):\n",
    "\n",
    "    log = file if hasattr(file,'write') else sys.stderr\n",
    "    traceback.print_stack(file=log)\n",
    "    log.write(warnings.formatwarning(message, category, filename, lineno, line))\n",
    "warnings.showwarning = warn_with_traceback\n",
    "\n",
    "# Add some functionality for ipython\n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')\n",
    "if is_interactive():\n",
    "    h5py.enable_ipython_completer()\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally the following parameters should not be changed, but retained here as parameters for flexibility\n",
    "\n",
    "# Location of code\n",
    "C_DIR='code-C'\n",
    "PYTHON_DIR='code-python'\n",
    "\n",
    "# Default location of runtime parameters - can be over-ridden by command line parameter\n",
    "FILE_PARAMETERS='input/input.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports of parameter and data classes, and of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of py-galaxies python routines\n",
    "sys.path.insert(1,PYTHON_DIR)\n",
    "\n",
    "# Commons is a module used to store run-time parameters that are used during other module imports.\n",
    "# It is a bit OTT as it contains very few entries and it is deleted after initialisation.\n",
    "import commons\n",
    "\n",
    "# The parameter class, used to store run-time parameters.\n",
    "from parameters import C_parameters\n",
    "\n",
    "# Read in parameters from yaml input files\n",
    "# If running interactively this is input/input.par; otherwise add option to read from command line.\n",
    "if is_interactive() or len(sys.argv)==1:\n",
    "    parameters=C_parameters(FILE_PARAMETERS)\n",
    "elif len(sys.argv)==2:\n",
    "    parameters=C_parameters(sys.argv[1])\n",
    "else:\n",
    "    raise ValueError('Usage: python3 L-Galaxies.py <input.yml>')\n",
    "# Define how verbose we want the terminal output to be\n",
    "verbosity=parameters.verbosity\n",
    "#commons.add('verbosity',verbosity)\n",
    "# Define which graphs do we want to process\n",
    "n_graph_start=parameters.n_graph_start\n",
    "n_graph_end=parameters.n_graph_end\n",
    "if n_graph_end==-1: n_graph_end=np.inf\n",
    "\n",
    "# Open graph input file: needs to come before F_set_dt and F_update_parameters\n",
    "graph_file=h5py.File(parameters.graph_file,'r')\n",
    "# Update parameters with attributes from graph_file\n",
    "parameters.F_update_parameters(graph_file)\n",
    "if n_graph_end == np.inf:\n",
    "    n_graph_end=parameters.n_graph\n",
    "elif n_graph_end>parameters.n_graph: \n",
    "    raise ValueError('Not enough graphs in input file')\n",
    "n_snap=parameters.n_snap\n",
    "\n",
    "# Dictionary of run-time variables that it would be too messy to pass individually.\n",
    "# It is permitted to add items to this dictionary in response to run-time flags.\n",
    "# It will be converted to a ctypes structure at the end of the initialisation phase.\n",
    "variables_dict=dict({\n",
    "    'dt_snap':0.,      # Time between snaps\n",
    "    'dt_halo':0.,      # Halo timestep\n",
    "    'dt_gal':0.,       # Galaxy timestep\n",
    "    'n_dt_halo':-1,    # Number of halo timesteps per snapshot\n",
    "    'n_dt_gal':-1      # Number of galaxy timesteps per halo timestep\n",
    "})\n",
    "\n",
    "# Need to set the timesteps now, because that information is needed to determine the structure of\n",
    "# the halo & subhalo classes and especially the galaxy arrays.\n",
    "# This loads in the snapshot times and determines the number of timesteps required.\n",
    "from misc import F_misc_set_dt\n",
    "F_misc_set_dt(parameters)\n",
    "if verbosity >=2:\n",
    "    for i_snap in range(n_snap):\n",
    "        print('i_snap, n_dt_halo, dt_halo, n_dt_gal, dt_gal')\n",
    "        print(i_snap, parameters.n_dt_halo[i_snap], parameters.dt_halo[i_snap], parameters.n_dt_gal[i_snap], parameters.dt_gal[i_snap])\n",
    "# This generates a class instance that holds the structure of the SFH arrays at all different timesteps\n",
    "b_SFH=parameters.b_SFH\n",
    "if b_SFH:\n",
    "    from sfh import C_sfh\n",
    "    sfh=C_sfh(parameters)\n",
    "    sfh.F_create_header_file(parameters)\n",
    "    \n",
    "# These parameters are needed at import, so save to commons here\n",
    "commons.update('b_SFH',parameters.b_SFH)\n",
    "if b_SFH: \n",
    "    commons.update('sfh_n_bin',sfh.n_bin)\n",
    "    # These counters need to be added to variables before saving as a C struct\n",
    "    variables_dict['i_dt_sfh']=-1\n",
    "    variables_dict['i_bin_sfh']=-1\n",
    "    \n",
    "# The conditional decorator and profilers\n",
    "from profiling import conditional_decorator\n",
    "\n",
    "# The graph class, used to store graphs for processing\n",
    "from graphs import C_graph\n",
    "\n",
    "# Halos\n",
    "from halos import F_halos_create_header_file\n",
    "F_halos_create_header_file()\n",
    "from halos import F_halos_initialise\n",
    "from halos import F_halos_template\n",
    "halo_template=F_halos_template(parameters)\n",
    "from halos import C_halo_output\n",
    "halo_output=C_halo_output(parameters)\n",
    "\n",
    "# Subhalos\n",
    "from subs import F_subs_create_header_file\n",
    "F_subs_create_header_file()\n",
    "from subs import F_subs_initialise\n",
    "from subs import F_subs_template\n",
    "sub_template=F_subs_template(parameters)\n",
    "from subs import C_sub_output\n",
    "sub_output=C_sub_output(parameters)\n",
    "\n",
    "# Galaxies\n",
    "from gals import F_gals_template\n",
    "gal_template=F_gals_template(parameters)\n",
    "parameters.gal_template=gal_template\n",
    "from gals import F_gals_create_header_file\n",
    "F_gals_create_header_file()\n",
    "from gals import C_gal_output\n",
    "gal_output=C_gal_output(parameters)\n",
    "\n",
    "# Now create the C parameters.h file.\n",
    "# *** DO NOT MODIFY PARAMETERS AFTER THIS POINT ***\n",
    "parameters.F_create_header_file()\n",
    "\n",
    "# Create the variables structure to be used for passing variables to C\n",
    "# *** DO NOT ADD VARIABLES AFTER THIS POINT ***\n",
    "from misc import F_misc_create_variables_structure_and_header_file\n",
    "C_variables=F_misc_create_variables_structure_and_header_file(variables_dict)\n",
    "variables=C_variables(variables_dict)\n",
    "del variables_dict\n",
    "\n",
    "# Create a header file containing the list of all other header files\n",
    "from misc import F_misc_create_all_headers_header_file\n",
    "F_misc_create_all_headers_header_file()\n",
    "\n",
    "# Import driver routine\n",
    "from push_snap import F_push_snap     # Propagates info from last snapshot to current one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation of SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start CPU profiling, if required.\n",
    "b_profile_cpu=parameters.b_profile_cpu\n",
    "commons.update('b_profile_cpu',b_profile_cpu)\n",
    "if b_profile_cpu:\n",
    "    from codetiming import Timer\n",
    "    from profiling import C_timer\n",
    "    timer = C_timer()\n",
    "    timer.start('Initialisation')\n",
    "\n",
    "# Create counter to locate graphs within the galaxy output file\n",
    "n_gal_graph_start=np.full(n_graph_end,parameters.NO_DATA_INT,dtype=np.int32)\n",
    "n_gal=0  # This is the total number of galaxies over all graphs\n",
    "\n",
    "# Create cooling table\n",
    "import cooling\n",
    "cooling_table = cooling.C_cooling(parameters)\n",
    "cooling_table.F_create_header_file()\n",
    "\n",
    "if b_profile_cpu: timer.stop('Initialisation')\n",
    "    \n",
    "# Start Memory profiling, if required\n",
    "b_profile_mem=parameters.b_profile_mem\n",
    "if b_profile_mem: \n",
    "    import tracemalloc as tm\n",
    "    tm.start()\n",
    "    # These lines attempt to filter out profiling memory itself; not clear how well it does that.\n",
    "    tm.Filter(False, tm.__file__)\n",
    "    if b_profile_cpu: tm.Filter(False, codetiming.__file__)\n",
    "    from profiling import C_mem\n",
    "    mem = C_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C integration\n",
    "\n",
    "Needs to be done after creation of all the header files, including for example that which stores the cooling tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C integration\n",
    "import ctypes\n",
    "\n",
    "# Make and load C-library\n",
    "from misc import F_misc_create_Makefile\n",
    "F_misc_create_Makefile(parameters)\n",
    "subprocess.run(['make'],cwd=C_DIR)\n",
    "L_C=ctypes.CDLL(C_DIR+'/lib_C.so')\n",
    "\n",
    "# Define interfaces to C functions: currently only one of these\n",
    "L_C.F_process_snap.argtypes=(np.ctypeslib.ndpointer(halo_template.dtype),ctypes.c_int,\n",
    "                             np.ctypeslib.ndpointer(sub_template.dtype),ctypes.c_int,\n",
    "                             np.ctypeslib.ndpointer(gal_template.dtype),ctypes.c_int,\n",
    "                             C_variables)\n",
    "L_C.F_process_snap.restype=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over graphs, snapshots, halos, implementing the SAM\n",
    "\n",
    "Note that loops over graphs can be done in parallel.\n",
    "\n",
    "Also, F_push_snap needs to be serial, but all halos can be processed in parallel in F_process_snap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over graphs\n",
    "for i_graph in range(n_graph_start,n_graph_end):\n",
    "    if verbosity >= 1: print('Processing graph',i_graph,flush=True)\n",
    "    graph_str = 'Graph{:03d}'.format(i_graph)\n",
    "    if b_profile_mem: mem.start(graph_str)\n",
    "    if b_profile_cpu: timer.start(graph_str)\n",
    "    graph = C_graph(i_graph,graph_file,parameters)\n",
    "    \n",
    "    # Keep track of location in galaxy output file\n",
    "    n_gal_graph_start[i_graph]=n_gal\n",
    "    \n",
    "    # Loop over snapshots\n",
    "    halos_last_snap = None\n",
    "    subs_last_snap = None\n",
    "    gals_last_snap = None\n",
    "    for i_snap in range(parameters.n_snap):\n",
    "        n_halo_this_snap=graph.snap_n_halo[i_snap]\n",
    "        if n_halo_this_snap == 0:\n",
    "            assert halos_last_snap == None\n",
    "            continue\n",
    "        if verbosity >= 2: print('Processing snapshot',i_snap,flush=True)\n",
    "            \n",
    "        # These timestepping parameters will be needed in the processing\n",
    "        variables.dt_snap=parameters.dt_snap[i_snap]\n",
    "        variables.dt_halo=parameters.dt_halo[i_snap]\n",
    "        variables.dt_gal=parameters.dt_gal[i_snap]\n",
    "        variables.n_dt_halo=parameters.n_dt_halo[i_snap]\n",
    "        variables.n_dt_gal=parameters.n_dt_gal[i_snap]\n",
    "            \n",
    "        # This is the ministep, needed to track star formation histories\n",
    "        if b_SFH:\n",
    "            i_dt_sfh=sfh.i_dt_snap[i_snap]-1   # This gives the ministep, BEFORE updating\n",
    "            variables.i_dt_sfh=i_dt_sfh\n",
    "            variables.i_bin_sfh=sfh.i_bin[i_dt_sfh]\n",
    "        \n",
    "        # Initialise halo and subhalo properties.\n",
    "        halos_this_snap = np.full(n_halo_this_snap,halo_template)\n",
    "        F_halos_initialise(halos_this_snap,i_graph,i_snap,graph,parameters)\n",
    "        n_sub_this_snap=graph.snap_n_sub[i_snap]\n",
    "        if n_sub_this_snap>0:\n",
    "            subs_this_snap = np.full(n_sub_this_snap,sub_template)\n",
    "            F_subs_initialise(subs_this_snap,i_graph,i_snap,graph,parameters)        \n",
    "        \n",
    "        # Propagate information from progenitors to this generation.\n",
    "        # Done as a push rather than a pull because sharing determined by progenitor.\n",
    "        # Have to do this even if no progenitors in order to initialise galaxy array.\n",
    "        # This is in python rather than C because of lots of graph lookups and variable-length arrays.\n",
    "        gals_this_snap=F_push_snap(halos_last_snap,halos_this_snap,subs_last_snap,subs_this_snap,\n",
    "                                   gals_last_snap,graph,parameters,variables)\n",
    "        del halos_last_snap\n",
    "        del subs_last_snap\n",
    "        del gals_last_snap\n",
    "        \n",
    "        # Perform the astrophysics\n",
    "        L_C.F_process_snap(halos_this_snap,n_halo_this_snap,subs_this_snap,n_sub_this_snap,\n",
    "                           gals_this_snap,len(gals_this_snap),variables)\n",
    "\n",
    "        # Once all halos have been done, output results\n",
    "        # This could instead be done on a halo-by-halo basis in F_process_halos\n",
    "        halo_output.append(halos_this_snap,parameters)\n",
    "        if n_sub_this_snap >0: sub_output.append(subs_this_snap,parameters)\n",
    "        if isinstance(gals_this_snap, np.ndarray):\n",
    "            gal_output.append(gals_this_snap,parameters)\n",
    "            n_gal+=len(gals_this_snap)\n",
    "            \n",
    "        # Rename this_snap data structures to last_snap\n",
    "        halos_last_snap=halos_this_snap\n",
    "        subs_last_snap=subs_this_snap\n",
    "        gals_last_snap=gals_this_snap\n",
    "\n",
    "        # Delete old references (so that create new objects on next snapshot)\n",
    "        del halos_this_snap\n",
    "        del subs_this_snap\n",
    "        del gals_this_snap\n",
    "\n",
    "    # Tidy up\n",
    "    del halos_last_snap\n",
    "    del subs_last_snap\n",
    "    del gals_last_snap\n",
    "    if b_profile_cpu: \n",
    "        timer.stop(graph_str)\n",
    "        if verbosity>1: print('graph processing time / s =',timer.timers[graph_str])\n",
    "    if b_profile_mem:\n",
    "        mem.stop(graph_str)\n",
    "        if verbosity>1: print('graph memory usage / bytes =',mem.mem[graph_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tidy up and exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if b_profile_mem: tm_snap = tm.take_snapshot()\n",
    "if b_profile_cpu: timer.start('Finalise')\n",
    "        \n",
    "# Flush buffers, close files and exit\n",
    "graph_file.close()\n",
    "halo_output.close()\n",
    "sub_output.close()\n",
    "gal_output.close()\n",
    "\n",
    "# Reopen galaxy output file to add graph start locations\n",
    "# Don't simply do this before originally closing the output file, as the close flushes output buffers\n",
    "gal_output=h5py.File(parameters.galaxy_file,'r+')\n",
    "# Sanity check that have correct number of galaxies\n",
    "assert n_gal==len(gal_output['Galaxies'])\n",
    "# Add graph start locations as new dataset\n",
    "dset=gal_output.create_dataset('Graph_start_locations',data=n_gal_graph_start,compression='gzip')\n",
    "# And close\n",
    "gal_output.close()\n",
    "\n",
    "if b_profile_cpu: \n",
    "    timer.stop('Finalise')\n",
    "    print(timer.timers['Finalise'])\n",
    "    print(timer)\n",
    "    timer.dump(parameters.profile_cpu_file)\n",
    "    for key in Timer.timers:\n",
    "        print('{:s}: {:g}'.format(key,Timer.timers[key]))\n",
    "    with open(parameters.profile_cpu_file, 'ab') as f:\n",
    "        pickle.dump(Timer.timers, f)\n",
    "if b_profile_mem: \n",
    "    mem.dump(parameters.profile_mem_file)\n",
    "    with open(parameters.profile_mem_file, 'ab') as f:\n",
    "        pickle.dump(tm_snap, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
