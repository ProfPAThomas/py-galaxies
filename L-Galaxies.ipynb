{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implementation of L-Galaxies\n",
    "\n",
    "This is a playground to test out the possibility of using `python` as an interface into L-Galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of generic python routines\n",
    "import astropy.constants as c\n",
    "import astropy.units as u\n",
    "import gc\n",
    "import h5py\n",
    "h5py.enable_ipython_completer()\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('whitegrid')\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters relating to the python code development.\n",
    "# Parameters relating to the SAM will be set in the input yaml file.\n",
    "\n",
    "# Location of code\n",
    "C_DIR='code-C'\n",
    "PYTHON_DIR='code-python'\n",
    "\n",
    "# Development limiter\n",
    "#n_GRAPH=np.inf\n",
    "n_GRAPH=5\n",
    "\n",
    "# Whether or not to pack halo instances with progenitor/descendant information\n",
    "b_HALO_FULL=True\n",
    "\n",
    "# Debug/testing switch\n",
    "b_DEBUG=True\n",
    "\n",
    "# Verbosity\n",
    "VERBOSITY=2 # 0 - Major program steps only; 1/2 - Major/minor Counters; 3 - Debugging diags.\n",
    "\n",
    "# Script parameters\n",
    "FILE_PARAMETERS='input/input.yml'\n",
    "b_DISPLAY_PARAMETERS=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of py-galaxies python routines\n",
    "sys.path.insert(1,PYTHON_DIR)\n",
    "\n",
    "# The parameter class, used to store run-time parameters\n",
    "from parameters import C_parameters\n",
    "\n",
    "# The graph class, used to store graphs for processing\n",
    "from graphs import C_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all the parameters of the run from the yaml and graph input files.\n",
    "\n",
    "parameters=C_parameters(FILE_PARAMETERS,VERBOSITY,b_DEBUG)\n",
    "if b_DISPLAY_PARAMETERS: print(parameters)\n",
    "\n",
    "# This code was supposed to read the particle mass, but that has disappeared!\n",
    "graph_file=h5py.File(parameters.graph_input_file,'r')\n",
    "for key, value in graph_file['Header'].attrs.items():\n",
    "    if b_DISPLAY_PARAMETERS: print(key,value)\n",
    "    exec('parameters.'+key+'=value')\n",
    "n_graph=len(graph_file['graph_lengths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over graphs\n",
    "for i_graph in range(n_graph):\n",
    "    if VERBOSITY>=2: print('Processing graph',i_graph)\n",
    "    graph=C_graph(i_graph,graph_file,parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Most of the work to be done in external routines, probably to be coded in C for efficiency.\n",
    "\n",
    "Here we just include the high-level driver routines.\n",
    "\n",
    "### I/O routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open graph data file\n",
    "def openGraphInput():\n",
    "    return h5py.File(parameters['inputFiles']['graphFile'],'r')\n",
    "\n",
    "# Close graph data file\n",
    "def closeGraphInput(graphInputFile):\n",
    "    graphInputFile.close()\n",
    "\n",
    "# Open galaxy output file\n",
    "def openGalaxyOutput(galaxyOutputFile):\n",
    "    galaxyOutputFile=h5py.File(parameters['outputFiles']['galaxyFile'],'w')\n",
    "\n",
    "# Close galaxy output file\n",
    "def closeGalaxyOutput():\n",
    "    galaxyOutputFile.close()\n",
    "\n",
    "# Open halo output file and create iobuffer and empty output dataset\n",
    "def openHaloOutput():\n",
    "    haloOutputFile=h5py.File(parameters['outputFiles']['haloFile'],'w')\n",
    "    haloOutputData=np.empty(io_nRec,dtype=dtype_halo)\n",
    "    haloOutputDataset=haloOutputFile.create_dataset('Halos',(0,),maxshape=(None,),dtype=dtype_halo,compression='gzip')\n",
    "    haloOutput_iRec=0\n",
    "    return haloOutputFile,haloOutputData,haloOutputDataset,haloOutput_iRec\n",
    "    \n",
    "# Close galaxy output file\n",
    "def closeHaloOutput(haloOutputFile,haloOutputData,haloOutputDataset,haloOutput_iRec):\n",
    "    # Write out halos remaining in output buffer\n",
    "    if haloOutput_iRec>0: haloOutput_iRec=flushOutput(haloOutput_iRec,haloOutputData,haloOutputDataset)\n",
    "    haloOutputFile.close()\n",
    "    return haloOutput_iRec\n",
    "\n",
    "# Output desired halo properties\n",
    "# For now just dump into a single dataset.  Will worry about whether we want a different format later\n",
    "# First need to define the dtype for the numpy structured array output.  Use 32 bit to save space.\n",
    "dtype_halo=np.dtype([\n",
    "    ('graphID',np.int32),\n",
    "    ('snapID',np.int32),\n",
    "    ('haloID',np.int32),\n",
    "    ('catalogID',np.int64),\n",
    "    ('mass',np.float32),\n",
    "    ('massBaryon',np.float32),\n",
    "    ('mass_fromProgenitors',np.float32)\n",
    "])\n",
    "def outputHalos(halos,haloOutputData,haloOutputDataset,haloOutput_iRec):\n",
    "    # Construct structured numpy array with desired data in\n",
    "    for halo in halos:\n",
    "        haloOutputData[haloOutput_iRec]['graphID']=halo.graphID\n",
    "        haloOutputData[haloOutput_iRec]['snapID']=halo.snapID\n",
    "        haloOutputData[haloOutput_iRec]['haloID']=halo.haloID\n",
    "        haloOutputData[haloOutput_iRec]['catalogID']=halo.catalogID\n",
    "        haloOutputData[haloOutput_iRec]['mass']=halo.mass\n",
    "        haloOutputData[haloOutput_iRec]['massBaryon']=halo.massBaryon\n",
    "        haloOutputData[haloOutput_iRec]['mass_fromProgenitors']=halo.mass_fromProgenitors\n",
    "        haloOutput_iRec+=1\n",
    "        if haloOutput_iRec==io_nRec: haloOutput_iRec=flushOutput(haloOutput_iRec,haloOutputData,haloOutputDataset)\n",
    "    return haloOutput_iRec\n",
    "    \n",
    "# Writes numpy output array to HDF5 dataset\n",
    "def flushOutput(nRec,outputData,outputDataset):\n",
    "    outputDataset.resize((outputDataset.shape[0]+nRec,))\n",
    "    outputDataset[-nRec:]=outputData[:nRec]\n",
    "    nRec=0\n",
    "    return nRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halo processing routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing halos \n",
    "def processHalo(halo):\n",
    "    if verbosity>=3: print('Processing halo ',halo.haloID)\n",
    "    if halo.done==True: \n",
    "        print('Warning: processHalo: halo ',str(halo),' already processed.')\n",
    "        assert False\n",
    "    readProperties(halo)\n",
    "    calcMassToDesc(halo)\n",
    "    # Omit gatherProgenitors for first generation of halos!\n",
    "    if halos_lastSnap != None: gatherProgenitors(halo)\n",
    "    setBaryonFraction(halo)\n",
    "#     fixStellarFraction(halo) # Dummy routine.\n",
    "    halo.done=True\n",
    "    \n",
    "def readProperties(halo):\n",
    "    # Reads halo properties from the input graph file\n",
    "    halo.catalogID=graphInputFile[halo.graphID][halo.snapID][halo.haloID].attrs.get('catalogID')\n",
    "    halo.mass=graphInputFile[halo.graphID][halo.snapID][halo.haloID].attrs.get('halo_mass')\n",
    "    return\n",
    "\n",
    "def calcMassToDesc(halo):\n",
    "    # Determines how much mass goes to each descendant, in proportion to desc_mass_contribution\n",
    "    desc_mass_contribution=graphInputFile[halo.graphID][halo.snapID][halo.haloID]['desc_mass_contribution']\n",
    "    desc_mass=np.array(desc_mass_contribution/np.sum(desc_mass_contribution)*halo.mass,dtype=np.float64)\n",
    "    halo.desc_mass=dict(zip(graphInputFile[halo.graphID][halo.snapID][halo.haloID]['desc_haloIDs'],desc_mass))\n",
    "\n",
    "def gatherProgenitors(halo):\n",
    "    # Collects information about material inherited from progenitors\n",
    "    # First halo in progenitor list\n",
    "    prog0_haloID=int(halos_lastSnap[0].haloID)\n",
    "    for prog_haloID in graphInputFile[halo.graphID][halo.snapID][halo.haloID]['prog_haloIDs']:\n",
    "        # Position in progenitor (lastSnap) halo list\n",
    "        if debugFlag and verbosity>=3 : print('prog_haloID =',prog_haloID)\n",
    "        prog_index_lastSnap=int(prog_haloID)-prog0_haloID\n",
    "        if debugFlag and verbosity>=3: print('prog_index_lastSnap =',prog_index_lastSnap)\n",
    "        # Check halo association\n",
    "        # This is needed because HDF5 may store halos in a different order - \n",
    "        # if this happens, will need to add code to do a search over all halos\n",
    "        # in lastSnap, or to rearrange into ascending order.\n",
    "        if debugFlag:\n",
    "            assert int(halos_lastSnap[prog_index_lastSnap].haloID) == int(prog_haloID)\n",
    "        # Now gather the appropriate information from the progenitor halo\n",
    "        halo.mass_fromProgenitors+=halos_lastSnap[prog_index_lastSnap].desc_mass[int(halo.haloID)]\n",
    "    return\n",
    "\n",
    "def setBaryonFraction(halo):\n",
    "    halo.massBaryon=fBaryon*max(halo.mass,halo.mass_fromProgenitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open graph input file\n",
    "# Note: can't pass undefined argument into function\n",
    "graphInputFile=openGraphInput()\n",
    "\n",
    "# Open output files\n",
    "# Note: can't pass undefined argument into function\n",
    "haloOutputFile,haloOutputData,haloOutputDataset,haloOutput_iRec=openHaloOutput()\n",
    "# Note: no attempt here to include sub-halos (galaxies).  Let's get halos right first!\n",
    "#openGalaxyOutput(galaxyOutputFile)\n",
    "\n",
    "# Iteratively loop over halos, doing whatever processing is required.\n",
    "# This assumes that halos properties depend only upon those halos in their immediate past in the merger graph.\n",
    "\n",
    "# Loop over MergerGraphs.\n",
    "nHalo=0\n",
    "#nHaloGraph=0\n",
    "#nHaloSnap=0\n",
    "for graphID in graphInputFile['/']:\n",
    "    if verbosity>=2: print('Processing graph',graphID)\n",
    "    graph=graphInputFile[graphID]\n",
    "    # Loop over snapshots from first to last.\n",
    "    halos_lastSnap = None\n",
    "    snapID_old=-1\n",
    "    for snapID in graph:  \n",
    "        # Not sure that these are guaranteed to be in increasing order, so put in this check\n",
    "        if snapID_old!=-1: assert int(snapID)==snapID_old+1\n",
    "        snapID_old=int(snapID)\n",
    "        if verbosity>=2: print('        snapshot',snapID)\n",
    "        snap=graph[snapID]\n",
    "        # Initialise halo properties\n",
    "        halos_thisSnap=[haloClass(graphID,snapID,haloID) for haloID in snap]\n",
    "        # Loop over halos in snapshot.\n",
    "        for halo in halos_thisSnap: \n",
    "            processHalo(halo)\n",
    "            nHalo +=1\n",
    "            if verbosity>=1 and nHalo%1000==0: print('Processed {:d} halos'.format(nHalo))\n",
    "        # Once all halos have been done, output results, update reference to lastSnap (and hence free memory)\n",
    "        haloOutput_iRec=outputHalos(halos_thisSnap,haloOutputData,haloOutputDataset,haloOutput_iRec)\n",
    "        del halos_lastSnap\n",
    "        #gc.collect() # garbage collection -- safe but very slow.\n",
    "        halos_lastSnap=halos_thisSnap\n",
    "        # Delete reference to this memory to free variable for new use.\n",
    "        del halos_thisSnap\n",
    "        # Temporary halt to limit to finite time\n",
    "        if nHalo>=nHaloMax:\n",
    "            closeHaloOutput(haloOutputFile,haloOutputData,haloOutputDataset,haloOutput_iRec)\n",
    "            assert False\n",
    "if not debugFlag: del halos_lastSnap\n",
    "\n",
    "# Close input file\n",
    "closeGraphInput(graphInputFile)\n",
    "\n",
    "# Close output files\n",
    "closeHaloOutput(haloOutputFile,haloOutputData,haloOutputDataset,haloOutput_iRec)\n",
    "#closeGalaxyOutput(galaxyOutputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(haloOutputFile)\n",
    "haloOutputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeHaloOutput(haloOutputFile,haloOutputData,haloOutputDataset,haloOutput_iRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([\n",
    "            halo.graphID,\n",
    "            halo.snapID,\n",
    "            halo.haloID,\n",
    "            halo.catalogID,\n",
    "            halo.mass,\n",
    "            halo.massBaryon,\n",
    "            halo.mass_fromProgenitors],\n",
    "        dtype=dtype_halo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeHaloOutput(haloOutputFile,haloOutputData,haloOutputDataset,haloOutput_iRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
