{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implementation of L-Galaxies\n",
    "\n",
    "This is a playground to test out the possibility of using `python` as an interface into L-Galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import astropy.constants as c\n",
    "import astropy.units as u\n",
    "import gc\n",
    "import h5py\n",
    "h5py.enable_ipython_completer()\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development limiter\n",
    "nHaloMax=10000\n",
    "\n",
    "# Debug/testing switch\n",
    "debugFlag=True\n",
    "\n",
    "# Verbosity\n",
    "verbosity=1 # 0 - Major program steps only; 1/2 - Major/minor Counters; 3 - Debugging diags.\n",
    "\n",
    "# Script parameters\n",
    "file_parameters='input/input.yml'\n",
    "displayParameters=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in parameters, graph file, etc.\n",
    "\n",
    "parameters=yaml.load(open(file_parameters),Loader=yaml.FullLoader)\n",
    "if displayParameters:\n",
    "    for item in parameters:\n",
    "        print(\"{:20s}: {}\".format(item,parameters[item]))\n",
    "\n",
    "fBaryon=parameters['cosmology']['fBaryon']['Value']\n",
    "io_nRec=parameters['performance']['io_nRec']['Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure for halos\n",
    "\n",
    "This is an interesting problem.  We have many requirements:\n",
    "- Must be fast – does this remove the possibility of using objects?\n",
    "- Must be flexible enough to respond to parameter choices (ideally at run time).\n",
    "- Must allow for variable-length arrays – I think that each halo will individually need to track what fraction of material it inherits from each progenitor.\n",
    "\n",
    "I think that the object-oriented way of doing it, as below, can easily adapt to run-time choices because it does not use long arrays.\n",
    "\n",
    "I have initially coded it using:\n",
    "- a list of graphs;\n",
    "- each graph is a dictionary of snapshots;\n",
    "- each snapshot is a dictionary of halos;\n",
    "- each halo is an instance of the `haloProperties` class.  \n",
    "\n",
    "There is a numpy.object dtype that would allow one to make that numpy arrays but I don't know if it offers any performance advantages or disadvantages.  The numpy objects can have arbitrary data added to them, but again I don't know if this flexibility means that they will be very slow (due to having to continually shift things around in memory).\n",
    "\n",
    "This is all very far from the current method that we have in L-Galaxies of defining a galaxy structure at compile time.\n",
    "\n",
    "## Data structure in graph HDF5 files\n",
    "\n",
    "Each graph is a group in the root `['/']` with labels `graphID` that appear to be non-consecutive: `group size=918`; `max(graphID)=1000`.  However, this could be because this is a subset of all graphs – in general may be working with subsets, so don't assume consecutive.\n",
    "\n",
    "### Snapshots\n",
    "\n",
    "Each snapshot is a group in `['/<graphID>']` with labels `snapID` running over all snapshots.\n",
    "\n",
    "### Halos\n",
    "\n",
    "Each halo is a group in `['/<graphID>/<snapID>']` with labels `haloID` that appear to run consecutively from 0, with `haloID` increasing with `snapID`.<br>\n",
    "<b>Note: they are in increasing string order, not numerical order.  This is a feature that needs fixing or it will break the code at some point.</b><br>\n",
    "<b>Note further: can just recode halo lists as dictionaries with `haloID` as lookup key.  That is much more robust and O(1) lookup.</b>\n",
    "\n",
    "Halos have attributes:\n",
    "* `catalogID` – ID in the original halo catalogue\n",
    "* `concentration` – ?\n",
    "* `halo_mass` – mass in Msun\n",
    "* `halo_nPart` – number of particles\n",
    "\n",
    "and datasets:\n",
    "* `centre_of_mass` – `np.float64[3]` array of centroid (?) in cMpc (?)\n",
    "* `desc_haloIDs` – `np.int64[<variable>]` array of `haloID`s of decendants\n",
    "* `desc_mass_contribution` – `np.int64[<variable>]` array of number of particles in common with each descendant (? – may contain non-associated particles)\n",
    "* `halo_velocity` – `np.float64[3]` array of mean velocity in km/s (?)\n",
    "* `prog_haloIDs` – `np.int64[<variable>]` array of `progID`s of decendants\n",
    "* `prog_mass_contribution` – `np.int64[<variable>]` array of number of particles in  \n",
    "common with each progenitor (? – may contain non-associated particles)\n",
    "\n",
    "Presumably we can add more properties, as desired.\n",
    "\n",
    "Halos also have subhalo groups contained within them.\n",
    "\n",
    "### Subhalos\n",
    "\n",
    "Each subhalo is a group in `['/<graphID>/<snapID>/<haloID>']` with labels `subhaloID` that run consecutively from 1 within each halo.  \\[It is not obvious that this is optimal – we may want to change.\\]<br>\n",
    "<b>Note: they are in increasing string order, not numerical order.  This is a feature that needs fixing or it will break the code at some point.</b><br>\n",
    "<b>Note further: can just recode halo lists as dictionaries with `haloID` as lookup key.  That is much more robust and O(1) lookup.</b>\n",
    "\n",
    "Subalos have attributes:\n",
    "* `subhalo_nPart` – number of particles\n",
    "\n",
    "and datasets:\n",
    "* `Subhalo_Part_IDs` – IDs of particles in subhalo\n",
    "* `Subhalo_Pos` – postions of particles in subhalo\n",
    "* `Subhalo_Vel` – velocities of particles in subhalo\n",
    "* `subhalo_mean_pos` – mean position of subhalo\n",
    "* `subhalo_mean_vel` – mean velocity of subhalo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This haloProperties class is just a container for all the halo properties.\n",
    "# It is not expected that it should have any sophisticated methods.\n",
    "# The constructer merely provides the unique labels for each halo;\n",
    "# other properties may then be added.\n",
    "# If this dynamic variable allocation is too slow, we could presumably find a way\n",
    "# to declare all the variables that we will need at the time of construction.\n",
    "class haloProperties:\n",
    "    # Constructor.\n",
    "    def __init__(self,graphID,snapID,haloID):\n",
    "        # These are (HDF5) strings\n",
    "        self.graphID=graphID\n",
    "        self.snapID=snapID\n",
    "        self.haloID=haloID\n",
    "        # Other halo properties.  Is it best to initialise to particular type or to None?\n",
    "        self.done=False\n",
    "        self.catalogID=-1\n",
    "        self.mass=0.\n",
    "        self.massBaryon=0.\n",
    "        self.mass_fromProgenitors=0.\n",
    "        self.massBaryon_fromProgenitors=0.\n",
    "        if parameters['modelSwitches']['HOD']: \n",
    "            self.massStars=0.\n",
    "            self.massStars_fromProgenitors=0.\n",
    "        # Not clear whether it is better to store information here about\n",
    "        # progenitors and descendants, which might result in variable-length\n",
    "        # data structure, or to look up from the HDF5 data file as required,\n",
    "        # which might require multiple access.\n",
    "        # If we want to specify the data size in advance, then we need to\n",
    "        # decide upon a maximum number of descendants to keep.  (I suspect\n",
    "        # that keeping as few as 3 descendants may be enough.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Most of the work to be done in external routines, probably to be coded in C for efficiency.\n",
    "\n",
    "Here we just include the high-level driver routines.\n",
    "\n",
    "### I/O routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open graph data file\n",
    "def openGraph():\n",
    "    graphFile=h5py.File(parameters['inputFiles']['graphFile'],'r')\n",
    "\n",
    "# Close graph data file\n",
    "def closeGraph():\n",
    "    graphFile.close()\n",
    "\n",
    "# Open galaxy output file\n",
    "def openGalaxyOutput():\n",
    "    galaxyOutputFile=h5py.File(parameters['outputFiles']['galaxyOutputFile'],'w')\n",
    "\n",
    "# Close galaxy output file\n",
    "def closeGalaxyOutput():\n",
    "    galaxyOutputFile.close()\n",
    "\n",
    "# Open halo output file and create iobuffer and empty output dataset\n",
    "def openHaloOutput():\n",
    "    haloOutputFile=h5py.File(parameters['outputFiles']['haloOutputFile'],'w')\n",
    "    io_haloData=np.empty(io_nRec,dtype=dtype_halo)\n",
    "    haloOutputData=haloOutputFile.create_dataset('Halos',(io_nRec),dtype=dtype_halo,chunks=(io_nRec))\n",
    "\n",
    "# Close galaxy output file\n",
    "def closeHaloOutput():\n",
    "    # Write out halos remaining in output buffer\n",
    "    if io_iRec>0: haloOutputData\n",
    "    haloOutputFile.close()\n",
    "    \n",
    "\n",
    "# Output desired halo properties\n",
    "# For now just dump into a single dataset.  Will worry about whether we want a different format later\n",
    "# First need to define the dtype for the numpy structured array output.  Use 32 bit to save space.\n",
    "dtype_halo=np.dtype([\n",
    "    ('graphID',np.int32),\n",
    "    ('snapID',np.int32),\n",
    "    ('haloID',np.int32),\n",
    "    ('catalogID',np.int64),\n",
    "    ('mass',np.float32),\n",
    "    ('massBaryon',np.float32),\n",
    "    ('mass_fromProgenitors',np.float32)\n",
    "])\n",
    "def outputHalos(halos):\n",
    "    # Construct structured numpy array with desired data in\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halo processing routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing halos \n",
    "def processHalo(halo):\n",
    "    if verbosity>=2: print('Processing halo ',halo.haloID)\n",
    "    if halo.done==True: \n",
    "        print('Warning: processHalo: halo ',str(halo),' already processed.')\n",
    "        return\n",
    "    readProperties(halo)\n",
    "    calcMassToDesc(halo)\n",
    "    # Omit gatherProgenitors for first generation of halos!\n",
    "    if haloProperties_lastSnap != None: gatherProgenitors(halo)\n",
    "    setBaryonFraction(halo)\n",
    "#     fixStellarFraction(halo) # Dummy routine.\n",
    "    halo.done=True\n",
    "    \n",
    "def readProperties(halo):\n",
    "    # Reads halo properties from the input graph file\n",
    "    halo.catalogID=graphFile[halo.graphID][halo.snapID][halo.haloID].attrs.get('catalogID')\n",
    "    halo.mass=graphFile[halo.graphID][halo.snapID][halo.haloID].attrs.get('halo_mass')\n",
    "    return\n",
    "\n",
    "def calcMassToDesc(halo):\n",
    "    # Determines how much mass goes to each descendant, in proportion to desc_mass_contribution\n",
    "    desc_mass_contribution=graphFile[halo.graphID][halo.snapID][halo.haloID]['desc_mass_contribution']\n",
    "    desc_mass=np.array(desc_mass_contribution/np.sum(desc_mass_contribution)*halo.mass,dtype=np.float64)\n",
    "    halo.desc_mass=dict(zip(graphFile[halo.graphID][halo.snapID][halo.haloID]['desc_haloIDs'],desc_mass))\n",
    "\n",
    "def gatherProgenitors(halo):\n",
    "    # Collects information about material inherited from progenitors\n",
    "    # First halo in progenitor list\n",
    "    prog0_haloID=int(haloProperties_lastSnap[0].haloID)\n",
    "    for prog_haloID in graphFile[halo.graphID][halo.snapID][halo.haloID]['prog_haloIDs']:\n",
    "        # Position in progenitor (lastSnap) halo list\n",
    "        if debugFlag and verbosity>=3 : print('prog_haloID =',prog_haloID)\n",
    "        prog_index_lastSnap=int(prog_haloID)-prog0_haloID\n",
    "        if debugFlag and verbosity>=3: print('prog_index_lastSnap =',prog_index_lastSnap)\n",
    "        # Check halo association\n",
    "        # This is needed because HDF5 may store halos in a different order - \n",
    "        # if this happens, will need to add code to do a search over all halos\n",
    "        # in lastSnap, or to rearrange into ascending order.\n",
    "        if debugFlag:\n",
    "            assert int(haloProperties_lastSnap[prog_index_lastSnap].haloID) == int(prog_haloID)\n",
    "        # Now gather the appropriate information from the progenitor halo\n",
    "        halo.mass_fromProgenitors+=haloProperties_lastSnap[prog_index_lastSnap].desc_mass[int(halo.haloID)]\n",
    "    return\n",
    "\n",
    "def setBaryonFraction(halo):\n",
    "    halo.massBaryon=fBaryon*np.max(halo.mass,halo.mass_fromProgenitors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open output files\n",
    "openHaloOutput()\n",
    "# Note: no attempt here to include sub-halos (galaxies).  Let's get halos right first!\n",
    "#openGalaxyOutput\n",
    "\n",
    "# Iteratively loop over halos, doing whatever processing is required.\n",
    "# This assumes that halos properties depend only upon those halos in \n",
    "# their immediate past in the merger graph.\n",
    "\n",
    "# Loop over MergerGraphs.\n",
    "nHalo=0\n",
    "#nHaloGraph=0\n",
    "#nHaloSnap=0\n",
    "for graphID in graphFile['/']:\n",
    "    if verbosity>=2: print('Processing graph',graphID)\n",
    "    graph=graphFile[graphID]\n",
    "    # Loop over snapshots from first to last.\n",
    "    haloProperties_lastSnap = None\n",
    "    for snapID in graph:  # Not sure that these are guaranteed to be in increasing order\n",
    "        if verbosity>=2: print('        snapshot',snapID)\n",
    "        snap=graph[snapID]\n",
    "        # Initialise halo properties\n",
    "        haloProperties_thisSnap=[haloProperties(graphID,snapID,haloID) for haloID in snap]\n",
    "        # Loop over halos in snapshot.\n",
    "        for halo in haloProperties_thisSnap: \n",
    "            processHalo(halo)\n",
    "            nHalo +=1\n",
    "            if verbosity>=1 and nHalo%1000==0: print('Processed {:d} halos'.format(nHalo))\n",
    "        # Once all halos have been done, output results, update reference to lastSnap (and hence free memory)\n",
    "        outputHalos(haloProperties_thisSnap)\n",
    "        del haloProperties_lastSnap\n",
    "        #gc.collect() # garbage collection -- safe but very slow.\n",
    "        haloProperties_lastSnap=haloProperties_thisSnap\n",
    "        # Delete reference to this memory to free variable for new use.\n",
    "        del haloProperties_thisSnap\n",
    "        # Temporary halt to limit to finite time\n",
    "        if nHalo==nHaloMax: assert False\n",
    "if not debugFlag: del haloProperties_lastSnap\n",
    "\n",
    "# Close output files\n",
    "closeHaloOutput()\n",
    "#closeGalaxyOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haloProperties_lastSnap[0].desc_mass['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_haloID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
